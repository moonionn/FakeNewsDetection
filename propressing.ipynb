{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:54.937871Z",
     "start_time": "2024-04-06T16:59:54.867662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10269 entries, 0 to 10268\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    10269 non-null  object \n",
      " 1   label                 10269 non-null  int64  \n",
      " 2   statement             10269 non-null  object \n",
      " 3   subject               10269 non-null  object \n",
      " 4   speaker               10269 non-null  object \n",
      " 5   job_title             7367 non-null   object \n",
      " 6   state_info            8058 non-null   object \n",
      " 7   party_affiliation     10269 non-null  object \n",
      " 8   barely_true_counts    10269 non-null  float64\n",
      " 9   false_counts          10269 non-null  float64\n",
      " 10  half_true_counts      10269 non-null  float64\n",
      " 11  mostly_true_counts    10269 non-null  float64\n",
      " 12  pants_on_fire_counts  10269 non-null  float64\n",
      " 13  context               10169 non-null  object \n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1283 entries, 0 to 1282\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1283 non-null   object \n",
      " 1   label                 1283 non-null   int64  \n",
      " 2   statement             1283 non-null   object \n",
      " 3   subject               1283 non-null   object \n",
      " 4   speaker               1283 non-null   object \n",
      " 5   job_title             954 non-null    object \n",
      " 6   state_info            1019 non-null   object \n",
      " 7   party_affiliation     1283 non-null   object \n",
      " 8   barely_true_counts    1283 non-null   float64\n",
      " 9   false_counts          1283 non-null   float64\n",
      " 10  half_true_counts      1283 non-null   float64\n",
      " 11  mostly_true_counts    1283 non-null   float64\n",
      " 12  pants_on_fire_counts  1283 non-null   float64\n",
      " 13  context               1266 non-null   object \n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 140.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1284 entries, 0 to 1283\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1284 non-null   object \n",
      " 1   label                 1284 non-null   int64  \n",
      " 2   statement             1284 non-null   object \n",
      " 3   subject               1284 non-null   object \n",
      " 4   speaker               1284 non-null   object \n",
      " 5   job_title             939 non-null    object \n",
      " 6   state_info            1005 non-null   object \n",
      " 7   party_affiliation     1284 non-null   object \n",
      " 8   barely_true_counts    1284 non-null   float64\n",
      " 9   false_counts          1284 non-null   float64\n",
      " 10  half_true_counts      1284 non-null   float64\n",
      " 11  mostly_true_counts    1284 non-null   float64\n",
      " 12  pants_on_fire_counts  1284 non-null   float64\n",
      " 13  context               1272 non-null   object \n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 140.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fake_train = 'dataset/fake_train.csv'\n",
    "fake_test = 'dataset/fake_test.csv'\n",
    "fake_valid = 'dataset/fake_valid.csv'\n",
    "train_df = pd.read_csv(fake_train)\n",
    "test_df = pd.read_csv(fake_test)\n",
    "valid_df = pd.read_csv(fake_valid)\n",
    "\n",
    "print(train_df.info())\n",
    "print(test_df.info())\n",
    "print(valid_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### =========================== 數據分析 ==========================="
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1e325763e0b674d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "數據集龐大，採直接drop掉有空值的欄位"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b20110bcd11b2b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6745 entries, 0 to 10268\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    6745 non-null   object \n",
      " 1   label                 6745 non-null   int64  \n",
      " 2   statement             6745 non-null   object \n",
      " 3   subject               6745 non-null   object \n",
      " 4   speaker               6745 non-null   object \n",
      " 5   job_title             6745 non-null   object \n",
      " 6   state_info            6745 non-null   object \n",
      " 7   party_affiliation     6745 non-null   object \n",
      " 8   barely_true_counts    6745 non-null   float64\n",
      " 9   false_counts          6745 non-null   float64\n",
      " 10  half_true_counts      6745 non-null   float64\n",
      " 11  mostly_true_counts    6745 non-null   float64\n",
      " 12  pants_on_fire_counts  6745 non-null   float64\n",
      " 13  context               6745 non-null   object \n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 790.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 865 entries, 0 to 1281\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    865 non-null    object \n",
      " 1   label                 865 non-null    int64  \n",
      " 2   statement             865 non-null    object \n",
      " 3   subject               865 non-null    object \n",
      " 4   speaker               865 non-null    object \n",
      " 5   job_title             865 non-null    object \n",
      " 6   state_info            865 non-null    object \n",
      " 7   party_affiliation     865 non-null    object \n",
      " 8   barely_true_counts    865 non-null    float64\n",
      " 9   false_counts          865 non-null    float64\n",
      " 10  half_true_counts      865 non-null    float64\n",
      " 11  mostly_true_counts    865 non-null    float64\n",
      " 12  pants_on_fire_counts  865 non-null    float64\n",
      " 13  context               865 non-null    object \n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 101.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 861 entries, 0 to 1283\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    861 non-null    object \n",
      " 1   label                 861 non-null    int64  \n",
      " 2   statement             861 non-null    object \n",
      " 3   subject               861 non-null    object \n",
      " 4   speaker               861 non-null    object \n",
      " 5   job_title             861 non-null    object \n",
      " 6   state_info            861 non-null    object \n",
      " 7   party_affiliation     861 non-null    object \n",
      " 8   barely_true_counts    861 non-null    float64\n",
      " 9   false_counts          861 non-null    float64\n",
      " 10  half_true_counts      861 non-null    float64\n",
      " 11  mostly_true_counts    861 non-null    float64\n",
      " 12  pants_on_fire_counts  861 non-null    float64\n",
      " 13  context               861 non-null    object \n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 100.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "valid_df = valid_df.dropna()\n",
    "print(train_df.info())\n",
    "print(test_df.info())\n",
    "print(valid_df.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:56.017909Z",
     "start_time": "2024-04-06T16:59:55.996803Z"
    }
   },
   "id": "b08010b0183db635",
   "execution_count": 240
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['dwayne-bohac',\n 'scott-surovell',\n 'barack-obama',\n 'robin-vos',\n 'duey-stroebel',\n 'robert-menendez',\n 'bernie-s',\n 'mitt-romney',\n 'george-will',\n 'gwen-moore',\n 'jack-lew',\n 'dennis-richardson',\n 'hillary-clinton',\n 'planned-parenthood-action-fund',\n 'nancy-pelosi',\n 'ted-nugent',\n 'pamela-geller',\n 'peter-kinder',\n 'nicholas-kettle',\n 'shelley-moore-capito',\n 'rick-scott',\n 'tom-cotton',\n 'ted-cruz',\n 'lee-leffingwell',\n 'kelly-ayotte',\n 'marco-rubio',\n 'jerry-patterson',\n 'john-boehner',\n 'rick-perry',\n 'ken-cuccinelli',\n 'andrew-cuomo',\n 'sid-miller',\n 'jim-barksdale',\n 'david-raynor',\n 'donald-trump',\n 'john-mccain',\n 'rudy-giuliani',\n 'john-barrasso',\n 'john-depetro',\n 'garnet-coleman',\n 'terry-mcauliffe',\n 'alfredo-gutierrez',\n 'elena-kagan',\n 'maurice-ferre',\n 'jeanne-shaheen',\n 'susan-happ',\n 'bill-white',\n 'bob-goodlatte',\n 'cory-booker',\n 'joe-biden',\n 'jim-skaggs',\n 'robert-sarvis',\n 'will-weatherford',\n 'mark-shields',\n 'alison-lundergan-grimes',\n 'mitch-mcconnell',\n 'frank-caprio',\n 'david-scott',\n 'scott-walker',\n 'donna-brazile',\n 'paul-ryan',\n 'mark-pocan',\n 'kathleen-sebelius',\n 'bruce-elfant',\n 'dave-yost',\n 'oregon-right-life-pac',\n 'patricia-morgan',\n 'dave-brat',\n 'mark-warner',\n 'rob-portman',\n 'john-cornyn',\n 'louie-gohmert',\n 'armond-budish',\n 'jeff-kruse',\n 'mike-haridopolos',\n 'paul-skip-stam',\n 'eric-cantor',\n 'ron-paul',\n 'gary-johnson',\n 'sheldon-whitehouse',\n 'pat-quinn',\n 'matthew-dowd',\n 'darrell-issa',\n 'michael-williams',\n 'alan-grayson',\n 'chris-christie',\n 'robert-jacquard',\n 'americas-health-insurance-plans',\n 'greg-abbott',\n 'david-cicilline',\n 'wendy-davis',\n 'marcy-kaptur',\n 'tamara-holder',\n 'hank-johnson',\n 'vincent-barrella',\n 'lamar-smith',\n 'bill-johnson',\n 'john-skvarla',\n 'daniel-mielke',\n 'blue-oregon',\n 'mark-neumann',\n 'tom-niehaus',\n 'sherrod-brown',\n 'john-kasich',\n 'ileana-ros-lehtinen',\n 'chris-moews',\n 'robby-mook',\n 'carolyn-maloney',\n 'lindsey-graham',\n 'mark-strama',\n 'patrick-leahy',\n 'agenda-project',\n 'rand-paul',\n 'james-bennett',\n 'tom-hughes',\n 'jeff-merkley',\n 'sheila-oliver',\n 'bill-richardson',\n 'paul-sarlo',\n 'connie-mack',\n 'allen-west',\n 'evan-feinberg',\n 'edith-ajello',\n 'doug-thomas',\n 'steve-latourette',\n 'trent-franks',\n 'ted-strickland',\n 'julian-castro',\n 'christine-sinicki',\n 'michele-bachmann',\n 'dan-patrick',\n 'newt-gingrich',\n 'tom-barrett',\n 'roy-blunt',\n 'chris-thomas',\n 'barney-simms',\n 'joyce-kaufman',\n 'christopher-plante',\n 'gerry-connolly',\n 'john-garamendi',\n 'donna-edwards',\n 'peter-kilmartin',\n 'roger-williams',\n 'david-dewhurst',\n 'josh-mandel',\n 'bill-clinton',\n 'chip-rogers',\n 'julius-jones',\n 'mike-huckabee',\n 'national-association-manufacturers',\n 'dinesh-dsouza',\n 'bill-foster',\n 'ken-legler',\n 'scott-henson',\n 'bob-mcdonnell',\n 'dwight-jones',\n 'lloyd-doggett',\n 'frank-guinta',\n 'cory-mason',\n 'mary-nolan',\n 'jim-steineke',\n 'joe-gibbons',\n 'mary-margaret-oliver',\n 'chuck-grassley',\n 'herb-garrett',\n 'peter-shumlin',\n 'national-organization-marriage',\n 'adam-kinzinger',\n 'donna-howard',\n 'john-bradley',\n 'glenn-grothman',\n 'joe-lieberman',\n 'jon-erpenbach',\n 'john-kerry',\n 'lou-greenwald',\n 'michael-burgess',\n 'ralph-nader',\n 'leticia-van-de-putte',\n 'john-plumb',\n 'tom-price',\n 'sondy-pope',\n 'carlos-curbelo',\n 'claudia-tenney',\n 'todd-hunter',\n 'sandy-adams',\n 'james-clyburn',\n 'reince-priebus',\n 'victoria-taft',\n 'rahm-emanuel',\n 'frank-annunziato',\n 'michael-steele',\n 'claire-mccaskill',\n 'joseph-crowley',\n 'chris-abele',\n 'tim-kaine',\n 'debbie-wasserman-schultz',\n 'jeff-morales',\n 'terry-jeffrey',\n 'bobby-jindal',\n 'chris-jacobs',\n 'phil-kerpen',\n 'joanne-kloppenburg',\n 'mike-pence',\n 'kay-bailey-hutchison',\n 'mike-foley',\n 'jackie-cilley',\n 'arsalan-iftikhar',\n 'marc-schare',\n 'sandra-williams',\n 'john-kitzhaber',\n 'adam-putnam',\n 'virginia-foxx',\n 'clay-pell',\n 'ginny-brown-waite',\n 'bill-proctor',\n 'kevin-dewine',\n 'john-pagliarini',\n 'diego-arene-morley',\n 'richard-codey',\n 'alberta-darling',\n 'cory-gardner',\n 'delia-garza',\n 'ed-gillespie',\n 'mike-lee',\n 'paul-broun',\n 'martin-omalley',\n 'matthew-hill',\n 'american-leadhership-pac',\n 'daniel-grace',\n 'sylvester-turner',\n 'chris-redfern',\n 'rob-cornilles',\n 'charles-schumer',\n 'steve-lonegan',\n 'bobby-scott',\n 'sean-duffy',\n 'angel-taveras',\n 'mike-rogers',\n 'kathleen-clyde',\n 'richard-ferruccio',\n 'terry-lawler',\n 'cokie-roberts',\n 'barbara-boxer',\n 'randy-forbes',\n 'joaquin-castro',\n 'joe-manchin',\n 'markos-moulitsas',\n 'fulton-county-health-and-wellness',\n 'brigid-shea',\n 'arthur-cyr',\n 'betty-sutton',\n 'jason-isaac',\n 'bill-hammond',\n 'health-care-america-now',\n 'miscellany-blue',\n 'jim-renacci',\n 'committee-our-childrens-future',\n 'tobias-read',\n 'rob-turner',\n 'mike-dewine',\n 'roy-cooper',\n 'friends-voter-owned-elections',\n 'monica-wehby',\n 'rod-monroe',\n 'ed-fitzgerald',\n 'jack-kingston',\n 'miriam-martinez',\n 'dan-micciche',\n 'todd-staples',\n 'tom-coburn',\n 'barbara-buono',\n 'rich-zipperer',\n 'mark-miller',\n 'kevin-de-leon',\n 'susana-martinez',\n 'henry-cuellar',\n 'deborah-ross',\n 'glenford-shibley',\n 'joseph-kyrillos',\n 'americans-prosperity-florida',\n 'joe-barton',\n 'jon-kyl',\n 'peter-palumbo',\n 'roy-barnes',\n 'pat-mccrory',\n 'don-zimmerman',\n 'betsy-miller-jones',\n 'marvin-pratt',\n 'dean-wright',\n 'sharron-angle',\n 'david-simas',\n 'helen-glover',\n 'fred-thompson',\n 'david-clarke-jr',\n 'lainey-melnick',\n 'caleb-rowden',\n 'brian-kemp',\n 'diane-allen',\n 'leonidas-raptakis',\n 'howard-dean',\n 'lou-ann-zelenik',\n 'joe-sestak',\n 'nickie-antonio',\n 'ward-armstrong',\n 'terri-lynn-land',\n 'blake-rocap',\n 'tim-canova',\n 'michael-reese',\n 'kamala-harris',\n 'julia-hurley',\n 'ellyn-bogdanoff',\n 'earl-blumenauer',\n 'ted-poe',\n 'senior-citizens-league',\n 'bill-maher',\n 'laurence-ehrhardt',\n 'jim-demint',\n 'texas-automobile-dealers-association',\n 'john-lewis',\n 'gina-raimondo',\n 'kitty-boitnott',\n 'nancy-devaney',\n 'chet-edwards',\n 'keep-conservatives-united',\n 'glenn-hegar',\n 'jon-runyan',\n 'senate-conservatives-fund',\n 'dennis-algiere',\n 'david-perdue',\n 'ted-gatsas',\n 'john-carter',\n 'ron-wyden',\n 'michael-turner',\n 'chuck-hagel',\n 'steve-archambault',\n 'peter-king',\n 'john-currie',\n 'upendra-chivukula',\n 'carol-hunstein',\n 'marcia-fudge',\n 'steve-cohen',\n 'jim-jordan',\n 'lon-burnam',\n 'george-voinovich',\n 'georgians-together',\n 'marsha-blackburn',\n 'mitch-daniels',\n 'oregon-healthy-kids',\n 'david-porter',\n 'kathleen-murphy',\n 'rafael-cruz',\n 'steve-oelrich',\n 'national-taxpayers-union',\n 'michael-roberson',\n 'ann-mclane-kuster',\n 'mark-hass',\n 'jim-sensenbrenner',\n 'charlie-smith',\n 'randi-shade',\n 'jim-webb',\n 'joe-garcia',\n 'john-obannon',\n 'john-lehman',\n 'ann-coulter',\n 'jason-stanford',\n 'ritch-workman',\n 'duncan-hunter-2',\n 'ann-kirkpatrick',\n 'ron-stephens',\n 'lena-taylor',\n 'carlos-beruff',\n 'tom-letson',\n 'keith-faber',\n 'johnny-isakson',\n 'john-tassoni-jr',\n 'steve-poizner',\n 'joe-defelice',\n 'bill-batchelder',\n 'progressohio',\n 'rich-golick',\n 'new-jersey-republican-state-committee',\n 'kathleen-peters',\n 'kirk-cox',\n 'ultraviolet',\n 'brian-sims',\n 'paul-howard',\n 'sam-adams',\n 'jack-berry',\n 'charles-rangel',\n 'greg-walden',\n 'amy-handlin',\n 'terry-moulton',\n 'john-loud',\n 'allan-fung',\n 'maggie-hassan',\n 'john-edwards',\n 'jerry-jones',\n 'harry-reid',\n 'marion-hammer',\n 'newsmax',\n 'ronald-renuart',\n 'david-quiroa',\n 'terry-gorman',\n 'wayne-powell',\n 'jeff-fitzgerald',\n 'alan-simpson',\n 'george-allen',\n 'john-mica',\n 'senate-majority-pac',\n 'tim-ryan',\n 'john-lombardi',\n 'chris-murphy',\n 'chris-coons',\n 'gus-bilirakis',\n 'nita-lowey',\n 'catherine-hanaway',\n 'elizabeth-warren',\n 'ben-cardin',\n 'vicki-martin',\n 'evan-bayh',\n 'jim-moran',\n 'ron-saunders',\n 'bill-weimer',\n 'ron-davis',\n 'peter-defazio',\n 'fred-risser',\n 'fred-karger',\n 'kurt-schrader',\n 'bill-lynch',\n 'tom-marino',\n 'scott-hassett',\n 'roberta-lange',\n 'karen-bass',\n 'peter-barca',\n 'reid-ribble',\n 'cheryl-grossman',\n 'carol-shea-porter',\n 'mark-udall',\n 'daily-caller',\n 'saxby-chambliss',\n 'doug-whitsett',\n 'loren-collins',\n 'paul-hirschbiel',\n 'gilberto-hinojosa',\n 'dennis-kucinich',\n 'colleen-deacon',\n 'stephanie-cutter',\n 'pat-toomey',\n 'mike-fasano',\n 'tim-cook',\n 'phil-king',\n 'andy-brown',\n 'david-dooley',\n 'alex-wan',\n 'mark-daniels',\n 'steve-stockman',\n 'nan-rich',\n 'william-perry',\n 'donna-campbell',\n 'stephen-zappala',\n 'christopher-blazejewski',\n 'kyleen-wright',\n 'tammy-baldwin',\n 'boyd-richie',\n 'ed-garvey',\n 'sergey-lavrov',\n 'mike-martinez',\n 'joe-pojman',\n 'bill-haslam',\n 'sandra-cunningham',\n 'robert-dimuccio',\n 'alcee-hastings',\n 'joseph-testa',\n 'robert-hagan',\n 'alfonso-lopez',\n 'blake-farenthold',\n 'marc-katz',\n 'pat-roberts',\n 'cathy-mcmorris-rodgers',\n 'tom-colicchio',\n 'robert-healey',\n 'c-wharton',\n 'allen-peake',\n 'vern-buchanan',\n 'amy-klobuchar',\n 'george-barker',\n 'rosa-delauro',\n 'jason-carter',\n 'jon-brien',\n 'chris-gregoire',\n 'bill-cassidy',\n 'jay-carney',\n 'gretchen-carlson',\n 'ben-nelson',\n 'steny-hoyer',\n 'donzella-james',\n 'elliott-naishtat',\n 'dan-lungren',\n 'kris-jordan',\n 'michael-thurmond',\n 'lynn-jenkins',\n 'michael-sullivan',\n 'dan-sullivan',\n 'art-acevedo',\n 'alissa-keny-guyer',\n 'robert-brown',\n 'jim-sullivan',\n 'elijah-cummings',\n 'bob-donovan',\n 'joshua-marquis',\n 'frederica-wilson',\n 'john-carlevale',\n 'mike-villarreal',\n 'joe-roman',\n 'lois-kolkhorst',\n 'dennis-jones',\n 'kim-simac',\n 'ken-plum',\n 'joe-brown',\n 'george-pataki',\n 'tom-harkin',\n 'molly-white',\n 'thomas-perez',\n 'milele-coggs',\n 'sheila-resseger',\n 'robert-hurt',\n 'don-beyer',\n 'frank-luntz',\n 'ron-ramsey',\n 'robert-reich',\n 'bob-gibbs',\n 'jim-huffman',\n 'ron-desantis',\n 'jim-hightower',\n 'gavin-newsom',\n 'mark-sickles',\n 'jeff-stone',\n 'sher-valenzuela',\n 'charlie-gonzalez',\n 'john-stone',\n 'chris-dodd',\n 'mark-clayton',\n 'kelli-stargel',\n 'john-duncan',\n 'ed-rendell',\n 'dale-kooyenga',\n 'goldie-taylor',\n 'catherine-taylor',\n 'mike-honda',\n 'josh-burgin',\n 'martin-frost',\n 'richard-blumenthal',\n 'kevin-brady',\n 'fred-upton',\n 'scott-rigell',\n 'herb-conaway',\n 'ellen-freidin',\n 'randy-hopper',\n 'mark-drewniak',\n 'howard-marklein',\n 'kurt-browning',\n 'vince-megna',\n 'united-fair-economy',\n 'mark-pryor',\n 'kathy-castor',\n 'erika-sanzi',\n 'chris-larson',\n 'paul-sadler',\n 'heather-fiorentino',\n 'debbie-stabenow',\n 'jim-kenney',\n 'pete-gallego',\n 'michelle-rehwinkel-vasilinda',\n 'j-james-rohack',\n 'john-wisniewski',\n 'danny-porter',\n 'kathleen-connell',\n 'george-turner',\n 'celine-gounder',\n 'portland-community-college',\n 'elise-stefanik',\n 'richard-saslaw',\n 'bryant-gumbel',\n 'orrin-hatch',\n 'kevin-otoole',\n 'tom-mcclintock',\n 'lee-fisher',\n 'chris-clark',\n 'juan-chuy-hinojosa',\n 'andy-duyck',\n 'phil-gingrey',\n 'lenar-whitney',\n 'daniel-mckee',\n 'dave-hunt',\n 'mary-burke',\n 'wes-riddle',\n 'steven-landes',\n 'joseph-joe-deshotel',\n 'thomas-sgouros-jr',\n 'americans-against-food-taxes',\n 'suzanne-bonamici',\n 'bill-oneill',\n 'tom-tancredo',\n 'haley-barbour',\n 'jeremy-bird',\n 'joe-straus',\n 'meria-carstarphen',\n 'larry-ahern',\n 'valerie-jarrett',\n 'new-approach-oregon',\n 'steve-spinnett',\n 'anna-throne-holst',\n 'jeff-atwater',\n 'linda-curtis',\n 'paul-workman',\n 'rob-teilhet',\n 'eddie-bernice-johnson',\n 'austan-goolsbee',\n 'jb-van-hollen',\n 'maryellen-oshaughnessy',\n 'our-oregon',\n 'sheila-jackson-lee',\n 'angela-bean',\n 'sheri-gallo',\n 'steve-scalise',\n 'jay-nixon',\n 'michael-j-gardiner',\n 'jeffrey-loria',\n 'nikki-haley',\n 'kyrsten-sinema',\n 'michael-mccaul',\n 'cliff-stearns',\n 'state-rep-brian-clem-d-salem',\n 'michelle-malkin',\n 'david-gregory',\n 'paula-dockery',\n 'lynda-rife',\n 'ami-bera',\n 'becky-moeller',\n 'vincent-fort',\n 'scott-randolph',\n 'kinky-friedman',\n 'george-w-bush',\n 'max-nofziger',\n 'jay-wiley',\n 'jeb-hensarling',\n 'jody-conradt',\n 'tim-griffin',\n 'dana-young',\n 'john-elkhay',\n 'steve-munisteri',\n 'nina-turner',\n 'john-taylor',\n 'patience-roggensack',\n 'barth-bracy',\n 'beto-orourke',\n 'ohio-federation-teachers',\n 'jeff-wentworth',\n 'marc-morial',\n 'bruce-hanna',\n 'ron-gerberry',\n 'donald-carcieri',\n 'don-gaetz',\n 'gerard-robinson',\n 'sam-stein',\n 'barry-smitherman',\n 'raymond-frank',\n 'bob-duffy',\n 'paul-begala',\n 'albio-sires',\n 'keith-parker',\n 'raymond-lahood',\n 'joe-heck',\n 'charlotte-bergmann',\n 'bill-spelman',\n 'gordon-challstrom',\n 'sabino-pio-renteria',\n 'jennifer-shilling',\n 'farouk-shami',\n 'robert-deuell',\n 'dan-boren',\n 'joyce-beatty',\n 'bonnie-reiss',\n 'gil-kerlikowske',\n 'jeffrey-grybowski',\n 'sarah-ponder',\n 'jeanine-pirro',\n 'bob-beckel',\n 'democratic-party-oregon',\n 'new-jersey-senate-democrats',\n 'mary-landrieu',\n 'mike-dovilla',\n 'john-e-sununu',\n 'carlos-lopez-cantera',\n 'karina-wood',\n 'henry-sanders',\n 'chris-sununu',\n 'jason-nassour',\n 'kiki-curls',\n 'nicholas-mattiello',\n 'kirk-watson',\n 'eric-greitens',\n 'barbara-sharief',\n 'generation-opportunity',\n 'kurt-bauer',\n 'al-gore',\n 'van-taylor',\n 'alison-littell-mchose',\n 'debra-medina',\n 'amy-kremer',\n 'bart-stupak',\n 'bernard-jackvony',\n 'patrick-lynch',\n 'bill-pascrell',\n 'sharon-day',\n 'carlos-trujillo',\n 'jim-bohl',\n 'david-holmes',\n 'jim-keffer',\n 'scott-bruun',\n 'jill-stein',\n 'jim-francesconi',\n 'nelson-wolff',\n 'karen-harrington',\n 'ronda-storms',\n 'jorge-ramos',\n 'texas-association-school-boards',\n 'steve-adler',\n 'marilinda-garcia',\n 'einer-elhauge',\n 'rebecca-bell-metereau',\n 'george-flinn',\n 'eddie-rodriguez',\n 'kathie-tovo',\n 'cathie-adams',\n 'martavius-jones',\n 'doris-kearns-goodwin',\n 'kathleen-ford',\n 'william-barber',\n 'nick-rahall',\n 'uber',\n 'donna-nesselbush',\n 'eddie-lucio-jr',\n 'renee-ellmers',\n 'hemant-mehta',\n 'don-willett',\n 'jim-mcgreevey',\n 'maciver-institute',\n 'paige-kreegel',\n 'bob-stacey',\n 'xi-jinping',\n 'dan-flynn',\n 'anne-nolan',\n 'john-huppenthal',\n 'frank-lautenberg',\n 'mike-polensek',\n 'levar-stoney',\n 'nick-fish',\n 'phil-robertson',\n 'ew-jackson',\n 'geraldine-thompson',\n 'loretta-sanchez',\n 'steve-ogden',\n 'cw-bill-young',\n 'leah-vukmir',\n 'robert-barber',\n 'dannel-malloy',\n 'bill-bennett',\n 'don-young',\n 'alliance-americas-future',\n 'steve-southerland',\n 'mario-loyola',\n 'david-alameel',\n 'emergency-committee-israel',\n 'bruce-rauner',\n 'john-thrasher',\n 'danny-tarkanian',\n 'dave-aronberg',\n 'pat-carlson',\n 'ellen-troxclair',\n 'bryce-reeves',\n 'caroline-casagrande',\n 'jim-waldman',\n 'jodie-laubenberg',\n 'jason-conger',\n 'bill-kristol',\n 'john-loughlin',\n 'mike-dudgeon',\n 'rob-wittman',\n 'jon-husted',\n 'anne-goodman',\n 'will-wynn',\n 'rick-kriseman',\n 'blanche-lincoln',\n 'rhue-reis',\n 'arthenia-joyner',\n 'donna-shalala',\n 'chris-mccalla',\n 'dave-marsden',\n 'diane-black',\n 'christopher-monckton',\n 'frank-wolf',\n 'thom-tillis',\n 'david-rivera',\n 'get-equal-texas',\n 'renee-unterman',\n 'kevin-flynn',\n 'committee-restore-americas-greatness',\n 'stefani-carter',\n 'jefferson-smith',\n 'lee-holloway',\n 'eric-gray',\n 'terry-russell',\n 'james-buchal',\n 'jack-reed',\n 'hugh-thompson',\n 'ron-maag',\n 'philip-van-cleave',\n 'rose-mary-grant',\n 'julie-lassa',\n 'jack-hanna',\n 'kay-hagan',\n 'silvestre-reyes',\n 'kirsten-gillibrand',\n 'tom-mechler',\n 'maria-sachs',\n 'mark-obenshain',\n 'wayne-christian',\n 'david-furhman',\n 'james-stegmaier',\n 'claire-suggs',\n 'taxpayer-association-oregon',\n 'john-fleming',\n 'ronald-rice',\n 'rosemary-lehmberg',\n 'stephen-nodine',\n 'kevin-mccarthy',\n 'michelle-nunn',\n 'corrine-brown',\n 'peter-pantuso',\n 'carol-morgan',\n 'kevin-reilly',\n 'anthony-gemma',\n 'chris-collins',\n 'roger-stone',\n 'christine-odonnell',\n 'matt-caldwell',\n 'david-bowen',\n 'david-barton',\n 'trey-martinez-fischer',\n 'john-buss',\n 'scott-maddox',\n 'steve-goreham',\n 'vicky-hartzler',\n 'ronnie-earle',\n 'bryan-hughes',\n 'new-jersey-tea-party',\n 'james-bell',\n 'penny-pritzker',\n 'jim-moore',\n 'lorraine-fende',\n 'kai-degner',\n 'robert-dold',\n 'seaworld',\n 'carlos-gimenez',\n 'steve-israel',\n 'tarina-keene',\n 'todd-richardson',\n 'pete-hegseth',\n 'rodney-ellis',\n 'steve-wise',\n 'susan-combs',\n 'deval-patrick',\n 'steve-loomis',\n 'herb-kohl',\n 'senate-republican-conference',\n 'tom-steyer',\n 'vance-smith',\n 'joe-wilkinson',\n 'michele-walsh',\n 'jim-mcdermott',\n 'charles-reed',\n 'zoe-lofgren',\n 'david-caton',\n 'scott-peters',\n 'john-klenke',\n 'jennifer-parrish',\n 'philip-keefe',\n 'jim-gilmore',\n 'maria-bartiromo',\n 'bill-post',\n 'mario-diaz-balart',\n 'everytown-gun-safety',\n 'teresa-ghilarducci',\n 'jack-roberts',\n 'josh-trevino',\n 'eva-marie-mancuso',\n 'andy-craig',\n 'ruben-kihuen',\n 'jose-rodriguez',\n 'chris-riley',\n 'doreen-costa',\n 'duriya-farooqui',\n 'michael-schrunk',\n 'hank-gilbert',\n 'dana-milbank',\n 'todd-tiahrt',\n 'ryan-frazier',\n 'charlie-sykes',\n 'tom-leppert',\n 'e-gordon-gee',\n 'gary-lambert',\n 'chris-dudley',\n 'jimmy-barrett',\n 'progress-austin-pac',\n 'duncan-hunter',\n 'tom-craddick',\n 'anitere-flores',\n 'george-p-bush',\n 'gail-collins',\n 'thomas-garrett-jr',\n 'david-segal',\n 'burrell-ellis',\n 'mike-hymes',\n 'bob-barr',\n 'gloria-romero-roses',\n 'charles-odimgbe',\n 'jim-rubens',\n 'gun-owners-america',\n 'roberto-dasilva',\n 'ted-kanavas',\n 'luis-alejo',\n 'van-jones',\n 'butch-conway',\n 'vernon-keenan',\n 'emanuel-cleaver',\n 'richard-morrison',\n 'roy-moore',\n 'greenville-gazette',\n 'julie-pace',\n 'carla-axtman',\n 'shawn-lindsay',\n 'richard-pan',\n 'lauren-hitt',\n 'roy-zimmerman',\n 'gary-black',\n 'stuart-sternberg',\n 'woody-degan',\n 'jack-latvala',\n 'linda-mcmahon',\n 'randy-neugebauer',\n 'martin-kiar',\n 'our-city-our-safety-our-choice',\n 'jeff-miller',\n 'burger-king',\n 'portland-public-schools',\n 'bill-seitz',\n 'mike-coffman',\n 'donna-garner',\n 'scott-garrett',\n 'ted-ankrum',\n 'doug-collins',\n 'john-thune',\n 'memphis-police-association',\n 'nina-perales',\n 'matt-mackowiak',\n 'tammy-duckworth',\n 'dan-ramos',\n 'akbar-al-baker',\n 'tom-corbett',\n 'jay-goyal',\n 'ken-mercer',\n 'ken-langone',\n 'kent-conrad',\n 'mike-scott',\n 'texans-economic-development',\n 'bee-moorhead',\n 'mark-begich',\n 'mike-gravel',\n 'james-langevin',\n 'us-census-bureau',\n 'linda-finn',\n 'jerry-falwell',\n 'julaine-appling',\n 'ruben-navarrette-jr',\n 'jamie-samons',\n 'john-raese',\n 'b-heath-mitchell',\n 'jonah-goldberg',\n 'charlene-lima',\n 'gary-painter',\n 'elizabeth-roberts',\n 'mark-kirk',\n 'james-vincent',\n 'brian-anderson',\n 'scott-desjarlais',\n 'joseph-mcnamara',\n 'suzanne-devlin',\n 'doug-macginnitie',\n 'john-sharp',\n ...]"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 了解label 有幾項\n",
    "train_df.label.unique().tolist()\n",
    "train_df.speaker.unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:56.496606Z",
     "start_time": "2024-04-06T16:59:56.484466Z"
    }
   },
   "id": "ccb2a914f7a6b8d3",
   "execution_count": 241
  },
  {
   "cell_type": "markdown",
   "source": [
    "将文本中提到的政党名称转换成数值标识符\n",
    "模型兼容性：大多数机器学习模型无法直接处理文本数据。将文本转换成数值（如通过将政党名称映射到特定的ID）可以让模型更容易地处理这些信息。\n",
    "\n",
    "数据简化：在您的数据集中，可能有多个变量或列与政党相关。通过将政党名称映射到唯一的ID上，可以简化这些信息，使得每个政党都有一个唯一、一致的标识符，减少数据的复杂性。\n",
    "\n",
    "数据分析：通过将文本分类转换为数值ID，您可以更容易地分析数据集中政党分布的模式。例如，您可以快速计算每个政党在数据集中出现的频率，或者探索政党与其他变量之间的关系。\n",
    "\n",
    "减少数据噪声：在原始数据中，相同政党的名称可能因为大小写、缩写或拼写错误而有所不同。将政党名称标准化并映射到一个唯一ID可以减少这种类型的噪声，提高数据质量。\n",
    "\n",
    "特征工程：这种转换是一种特征工程的形式，它可以帮助提高模型的性能。通过识别数据中最频繁的政党并为它们分配ID，您可以创建一个有意义的特征，该特征可能对于预测任务（如分类新闻文章为真实或假新闻）来说是有用的。\n",
    "\n",
    "泛化能力：为不频繁出现或未知的政党分配一个通用ID（如方法中使用的len(set(frequent_parties.values()))）可以提高模型对新或罕见政党的泛化能力。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5230bf231ea9e133"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'republican': 3405, 'democrat': 2621, 'none': 367, 'independent': 126, 'newsmaker': 36}\n",
      "{'republican': 0, 'democrat': 1, 'none': 2, 'independent': 3, 'newsmaker': 4}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "######Party######\n",
    "#################\n",
    "\n",
    "# 首先获取前5个最频繁出现的政党及其计数\n",
    "frequent_parties_series = train_df['party_affiliation'].str.lower().value_counts()[:5]\n",
    "\n",
    "# 转换为字典，此时键是政党名称，值是出现的频次\n",
    "frequent_parties_dict = frequent_parties_series.to_dict()\n",
    "print(frequent_parties_dict)\n",
    "# 如果您想将政党名称映射到它们的排名（而不是频次）\n",
    "frequent_parties = {party: rank for rank, (party, freq) in enumerate(frequent_parties_dict.items(), start=0)}\n",
    "print(frequent_parties)\n",
    "def get_party_id(party):\n",
    "  if isinstance(party, str):\n",
    "    matched = [pt for pt in frequent_parties if pt in party.lower() ]\n",
    "    if len(matched)>0:\n",
    "      return frequent_parties[matched[0]]\n",
    "    else:\n",
    "      return len(set(frequent_parties.values())) \n",
    "  else:\n",
    "    return len(set(frequent_parties.values())) \n",
    "  \n",
    "\n",
    "train_df['party_affiliation'] = train_df['party_affiliation'].apply(get_party_id)\n",
    "valid_df['party_affiliation'] = valid_df['party_affiliation'].apply(get_party_id)\n",
    "test_df['party_affiliation'] = test_df['party_affiliation'].apply(get_party_id)\n",
    "\n",
    "print(len(set(frequent_parties.values())))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:57.414022Z",
     "start_time": "2024-04-06T16:59:57.403161Z"
    }
   },
   "id": "b1451ee55da7034",
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               id  label                                          statement  \\\n0       2635.json      0  Says the Annies List political group supports ...   \n1      10540.json      1  When did the decline of coal start? It started...   \n2        324.json      2  Hillary Clinton agrees with John McCain \"by vo...   \n5      12465.json      3  The Chicago Bears have had more starting quart...   \n7        153.json      1  \"I'm the only person on this stage who has wor...   \n...           ...    ...                                                ...   \n10256  13344.json      5  Recently though, the media has reported on tho...   \n10257  13239.json      4  Stopped by Smiley Cookie to pick up some great...   \n10259  11018.json      4  The Supreme Courts views are radically out of ...   \n10260   2930.json      1  When it comes to the state deficit, Wisconsin ...   \n10268   1155.json      5  The Department of Veterans Affairs has a manua...   \n\n                                     subject          speaker  \\\n0                                   abortion     dwayne-bohac   \n1         energy,history,job-accomplishments   scott-surovell   \n2                             foreign-policy     barack-obama   \n5                                  education        robin-vos   \n7                                     ethics     barack-obama   \n...                                      ...              ...   \n10256                              elections    john-rafferty   \n10257                                   food     donald-trump   \n10259  gays-and-lesbians,polls,supreme-court         ted-cruz   \n10260                           state-budget  alberta-darling   \n10268                   health-care,veterans   michael-steele   \n\n                                           job_title    state_info  \\\n0                               State representative         Texas   \n1                                     State delegate      Virginia   \n2                                          President      Illinois   \n5                         Wisconsin Assembly speaker     Wisconsin   \n7                                          President      Illinois   \n...                                              ...           ...   \n10256                                  State Senator  Pennsylvania   \n10257                                President-Elect      New York   \n10259                                        Senator         Texas   \n10260                    State Senator, 8th District     Wisconsin   \n10268  chairman of the Republican National Committee      Maryland   \n\n       party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n0                      0                 0.0           1.0               0.0   \n1                      1                 0.0           0.0               1.0   \n2                      1                70.0          71.0             160.0   \n5                      0                 0.0           3.0               2.0   \n7                      1                70.0          71.0             160.0   \n...                  ...                 ...           ...               ...   \n10256                  0                 0.0           0.0               0.0   \n10257                  0                63.0         114.0              51.0   \n10259                  0                36.0          33.0              15.0   \n10260                  0                 1.0           1.0               2.0   \n10268                  0                 0.0           1.0               1.0   \n\n       mostly_true_counts  pants_on_fire_counts  \\\n0                     0.0                   0.0   \n1                     1.0                   0.0   \n2                   163.0                   9.0   \n5                     5.0                   1.0   \n7                   163.0                   9.0   \n...                   ...                   ...   \n10256                 0.0                   1.0   \n10257                37.0                  61.0   \n10259                19.0                   8.0   \n10260                 1.0                   1.0   \n10268                 0.0                   2.0   \n\n                                        context  \n0                                      a mailer  \n1                               a floor speech.  \n2                                        Denver  \n5                     a an online opinion-piece  \n7      a Democratic debate in Philadelphia, Pa.  \n...                                         ...  \n10256                                 a debate.  \n10257                          a Facebook post.  \n10259                       an interview on NPR  \n10260                    a television interview  \n10268                      a Fox News interview  \n\n[6745 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party_affiliation</th>\n      <th>barely_true_counts</th>\n      <th>false_counts</th>\n      <th>half_true_counts</th>\n      <th>mostly_true_counts</th>\n      <th>pants_on_fire_counts</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2635.json</td>\n      <td>0</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>a mailer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10540.json</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>a floor speech.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324.json</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>1</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>Denver</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12465.json</td>\n      <td>3</td>\n      <td>The Chicago Bears have had more starting quart...</td>\n      <td>education</td>\n      <td>robin-vos</td>\n      <td>Wisconsin Assembly speaker</td>\n      <td>Wisconsin</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>a an online opinion-piece</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>153.json</td>\n      <td>1</td>\n      <td>\"I'm the only person on this stage who has wor...</td>\n      <td>ethics</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>1</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>a Democratic debate in Philadelphia, Pa.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10256</th>\n      <td>13344.json</td>\n      <td>5</td>\n      <td>Recently though, the media has reported on tho...</td>\n      <td>elections</td>\n      <td>john-rafferty</td>\n      <td>State Senator</td>\n      <td>Pennsylvania</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>a debate.</td>\n    </tr>\n    <tr>\n      <th>10257</th>\n      <td>13239.json</td>\n      <td>4</td>\n      <td>Stopped by Smiley Cookie to pick up some great...</td>\n      <td>food</td>\n      <td>donald-trump</td>\n      <td>President-Elect</td>\n      <td>New York</td>\n      <td>0</td>\n      <td>63.0</td>\n      <td>114.0</td>\n      <td>51.0</td>\n      <td>37.0</td>\n      <td>61.0</td>\n      <td>a Facebook post.</td>\n    </tr>\n    <tr>\n      <th>10259</th>\n      <td>11018.json</td>\n      <td>4</td>\n      <td>The Supreme Courts views are radically out of ...</td>\n      <td>gays-and-lesbians,polls,supreme-court</td>\n      <td>ted-cruz</td>\n      <td>Senator</td>\n      <td>Texas</td>\n      <td>0</td>\n      <td>36.0</td>\n      <td>33.0</td>\n      <td>15.0</td>\n      <td>19.0</td>\n      <td>8.0</td>\n      <td>an interview on NPR</td>\n    </tr>\n    <tr>\n      <th>10260</th>\n      <td>2930.json</td>\n      <td>1</td>\n      <td>When it comes to the state deficit, Wisconsin ...</td>\n      <td>state-budget</td>\n      <td>alberta-darling</td>\n      <td>State Senator, 8th District</td>\n      <td>Wisconsin</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>a television interview</td>\n    </tr>\n    <tr>\n      <th>10268</th>\n      <td>1155.json</td>\n      <td>5</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>health-care,veterans</td>\n      <td>michael-steele</td>\n      <td>chairman of the Republican National Committee</td>\n      <td>Maryland</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>a Fox News interview</td>\n    </tr>\n  </tbody>\n</table>\n<p>6745 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:57.831703Z",
     "start_time": "2024-04-06T16:59:57.822744Z"
    }
   },
   "id": "850274d5c7220c28",
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u.s. senator': 0, 'president': 1, 'governor': 2, 'president-elect': 3, 'u.s. representative': 4, 'presidential candidate': 5, 'state senator': 6, 'state representative': 7, 'former governor': 8, 'milwaukee county executive': 9, 'senator': 10, 'u.s. house of representatives': 11, 'attorney': 12, 'congressman': 13, 'governor of new jersey': 14}\n"
     ]
    },
    {
     "data": {
      "text/plain": "               id  label                                          statement  \\\n0       2635.json      0  Says the Annies List political group supports ...   \n1      10540.json      1  When did the decline of coal start? It started...   \n2        324.json      2  Hillary Clinton agrees with John McCain \"by vo...   \n5      12465.json      3  The Chicago Bears have had more starting quart...   \n7        153.json      1  \"I'm the only person on this stage who has wor...   \n...           ...    ...                                                ...   \n10256  13344.json      5  Recently though, the media has reported on tho...   \n10257  13239.json      4  Stopped by Smiley Cookie to pick up some great...   \n10259  11018.json      4  The Supreme Courts views are radically out of ...   \n10260   2930.json      1  When it comes to the state deficit, Wisconsin ...   \n10268   1155.json      5  The Department of Veterans Affairs has a manua...   \n\n                                     subject          speaker  job_title  \\\n0                                   abortion     dwayne-bohac          7   \n1         energy,history,job-accomplishments   scott-surovell         15   \n2                             foreign-policy     barack-obama          1   \n5                                  education        robin-vos         15   \n7                                     ethics     barack-obama          1   \n...                                      ...              ...        ...   \n10256                              elections    john-rafferty          6   \n10257                                   food     donald-trump          1   \n10259  gays-and-lesbians,polls,supreme-court         ted-cruz         10   \n10260                           state-budget  alberta-darling          6   \n10268                   health-care,veterans   michael-steele         15   \n\n         state_info  party_affiliation  barely_true_counts  false_counts  \\\n0             Texas                  0                 0.0           1.0   \n1          Virginia                  1                 0.0           0.0   \n2          Illinois                  1                70.0          71.0   \n5         Wisconsin                  0                 0.0           3.0   \n7          Illinois                  1                70.0          71.0   \n...             ...                ...                 ...           ...   \n10256  Pennsylvania                  0                 0.0           0.0   \n10257      New York                  0                63.0         114.0   \n10259         Texas                  0                36.0          33.0   \n10260     Wisconsin                  0                 1.0           1.0   \n10268      Maryland                  0                 0.0           1.0   \n\n       half_true_counts  mostly_true_counts  pants_on_fire_counts  \\\n0                   0.0                 0.0                   0.0   \n1                   1.0                 1.0                   0.0   \n2                 160.0               163.0                   9.0   \n5                   2.0                 5.0                   1.0   \n7                 160.0               163.0                   9.0   \n...                 ...                 ...                   ...   \n10256               0.0                 0.0                   1.0   \n10257              51.0                37.0                  61.0   \n10259              15.0                19.0                   8.0   \n10260               2.0                 1.0                   1.0   \n10268               1.0                 0.0                   2.0   \n\n                                        context  \n0                                      a mailer  \n1                               a floor speech.  \n2                                        Denver  \n5                     a an online opinion-piece  \n7      a Democratic debate in Philadelphia, Pa.  \n...                                         ...  \n10256                                 a debate.  \n10257                          a Facebook post.  \n10259                       an interview on NPR  \n10260                    a television interview  \n10268                      a Fox News interview  \n\n[6745 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subject</th>\n      <th>speaker</th>\n      <th>job_title</th>\n      <th>state_info</th>\n      <th>party_affiliation</th>\n      <th>barely_true_counts</th>\n      <th>false_counts</th>\n      <th>half_true_counts</th>\n      <th>mostly_true_counts</th>\n      <th>pants_on_fire_counts</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2635.json</td>\n      <td>0</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>7</td>\n      <td>Texas</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>a mailer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10540.json</td>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>15</td>\n      <td>Virginia</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>a floor speech.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324.json</td>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>1</td>\n      <td>Illinois</td>\n      <td>1</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>Denver</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12465.json</td>\n      <td>3</td>\n      <td>The Chicago Bears have had more starting quart...</td>\n      <td>education</td>\n      <td>robin-vos</td>\n      <td>15</td>\n      <td>Wisconsin</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>a an online opinion-piece</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>153.json</td>\n      <td>1</td>\n      <td>\"I'm the only person on this stage who has wor...</td>\n      <td>ethics</td>\n      <td>barack-obama</td>\n      <td>1</td>\n      <td>Illinois</td>\n      <td>1</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>a Democratic debate in Philadelphia, Pa.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10256</th>\n      <td>13344.json</td>\n      <td>5</td>\n      <td>Recently though, the media has reported on tho...</td>\n      <td>elections</td>\n      <td>john-rafferty</td>\n      <td>6</td>\n      <td>Pennsylvania</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>a debate.</td>\n    </tr>\n    <tr>\n      <th>10257</th>\n      <td>13239.json</td>\n      <td>4</td>\n      <td>Stopped by Smiley Cookie to pick up some great...</td>\n      <td>food</td>\n      <td>donald-trump</td>\n      <td>1</td>\n      <td>New York</td>\n      <td>0</td>\n      <td>63.0</td>\n      <td>114.0</td>\n      <td>51.0</td>\n      <td>37.0</td>\n      <td>61.0</td>\n      <td>a Facebook post.</td>\n    </tr>\n    <tr>\n      <th>10259</th>\n      <td>11018.json</td>\n      <td>4</td>\n      <td>The Supreme Courts views are radically out of ...</td>\n      <td>gays-and-lesbians,polls,supreme-court</td>\n      <td>ted-cruz</td>\n      <td>10</td>\n      <td>Texas</td>\n      <td>0</td>\n      <td>36.0</td>\n      <td>33.0</td>\n      <td>15.0</td>\n      <td>19.0</td>\n      <td>8.0</td>\n      <td>an interview on NPR</td>\n    </tr>\n    <tr>\n      <th>10260</th>\n      <td>2930.json</td>\n      <td>1</td>\n      <td>When it comes to the state deficit, Wisconsin ...</td>\n      <td>state-budget</td>\n      <td>alberta-darling</td>\n      <td>6</td>\n      <td>Wisconsin</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>a television interview</td>\n    </tr>\n    <tr>\n      <th>10268</th>\n      <td>1155.json</td>\n      <td>5</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>health-care,veterans</td>\n      <td>michael-steele</td>\n      <td>15</td>\n      <td>Maryland</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>a Fox News interview</td>\n    </tr>\n  </tbody>\n</table>\n<p>6745 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "#######Job#######\n",
    "#################\n",
    "\n",
    "frequent_job_series = train_df['job_title'].str.lower().value_counts()[:15]\n",
    "# frequent_job_series\n",
    "# 转换为字典，此时键是政党名称，值是出现的频次\n",
    "frequent_job_dict = frequent_job_series.to_dict()\n",
    "frequent_job = {party: rank for rank, (party, freq) in enumerate(frequent_job_dict.items(), start=0)}\n",
    "print(frequent_job)\n",
    "\n",
    "def get_job_id(job):\n",
    "    if isinstance(job, str):\n",
    "        matched = [jt for jt in frequent_job if jt in job.lower()]\n",
    "        if len(matched) > 0:\n",
    "            return frequent_job[matched[0]]\n",
    "        else:\n",
    "            return len(set(frequent_job.values()))\n",
    "    else:\n",
    "        return len(set(frequent_job.values()))\n",
    "\n",
    "# 确保使用正确的函数名\n",
    "train_df['job_title'] = train_df['job_title'].apply(get_job_id)\n",
    "valid_df['job_title'] = valid_df['job_title'].apply(get_job_id)\n",
    "test_df['job_title'] = test_df['job_title'].apply(get_job_id)\n",
    "\n",
    "# 打印出job_id列的唯一值来验证结果\n",
    "# print(train_df['job_id'].unique())\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:58.394203Z",
     "start_time": "2024-04-06T16:59:58.371062Z"
    }
   },
   "id": "870fdcdde0d5fde5",
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news release': 0, 'interview': 1, 'press release': 2, 'speech': 3, 'tv': 4, 'tweet': 5, 'campaign': 6, 'television': 4, 'debate': 7, 'news conference': 8, 'facebook': 5, 'press conference': 8, 'radio': 9, 'e-mail': 10, 'email': 10, 'mail': 10, 'social media': 5, 'twitter': 5, 'blog': 11, 'article': 11, 'comment': 12, 'web': 11}\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "#####Context#####\n",
    "#################\n",
    "\n",
    "frequent_context = {'news release' : 0, 'interview' : 1, 'press release' : 2, \n",
    "                   'speech' : 3, 'tv' : 4, 'tweet' : 5, 'campaign' : 6, \n",
    "                   'television' : 4, 'debate' : 7, 'news conference' : 8, \n",
    "                   'facebook' : 5, 'press conference' : 8, 'radio' : 9, \n",
    "                   'e-mail' : 10, 'email' : 10, 'mail' : 10, 'social media' : 5,\n",
    "                   'twitter' : 5, 'blog':11, 'article':11,'comment':12, 'web':11}\n",
    "\n",
    "print(frequent_context)\n",
    "\n",
    "\n",
    "def get_venue_id(venue):\n",
    "  if isinstance(venue, str):\n",
    "    matched = [ven for ven in frequent_context if ven in venue.lower() ]\n",
    "    if len(matched)>0:\n",
    "      return frequent_context[matched[0]]\n",
    "    else:\n",
    "      return len(set(frequent_context.values())) \n",
    "  else:\n",
    "    return len(set(frequent_context.values()))\n",
    "  \n",
    "\n",
    "train_df['context'] = train_df['context'].apply(get_venue_id)\n",
    "valid_df['context'] = valid_df['context'].apply(get_venue_id)\n",
    "test_df['context'] = test_df['context'].apply(get_venue_id)\n",
    "\n",
    "print(len(set(frequent_context.values())))\n",
    "\n",
    "# train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:58.988845Z",
     "start_time": "2024-04-06T16:59:58.966676Z"
    }
   },
   "id": "a22b8d2ce8b72626",
   "execution_count": 245
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 移除部分欄位\n",
    "train_df = train_df.drop(columns=['id', 'speaker', 'state_info', 'subject'])\n",
    "test_df = test_df.drop(columns=['id', 'speaker', 'state_info', 'subject'])\n",
    "valid_df = valid_df.drop(columns=['id', 'speaker', 'state_info', 'subject'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:59:59.595186Z",
     "start_time": "2024-04-06T16:59:59.589789Z"
    }
   },
   "id": "4afb5c6242525e1d",
   "execution_count": 246
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       label                                          statement  job_title  \\\n0          0  Says the Annies List political group supports ...          7   \n1          1  When did the decline of coal start? It started...         15   \n2          2  Hillary Clinton agrees with John McCain \"by vo...          1   \n5          3  The Chicago Bears have had more starting quart...         15   \n7          1  \"I'm the only person on this stage who has wor...          1   \n...      ...                                                ...        ...   \n10256      5  Recently though, the media has reported on tho...          6   \n10257      4  Stopped by Smiley Cookie to pick up some great...          1   \n10259      4  The Supreme Courts views are radically out of ...         10   \n10260      1  When it comes to the state deficit, Wisconsin ...          6   \n10268      5  The Department of Veterans Affairs has a manua...         15   \n\n       party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n0                      0                 0.0           1.0               0.0   \n1                      1                 0.0           0.0               1.0   \n2                      1                70.0          71.0             160.0   \n5                      0                 0.0           3.0               2.0   \n7                      1                70.0          71.0             160.0   \n...                  ...                 ...           ...               ...   \n10256                  0                 0.0           0.0               0.0   \n10257                  0                63.0         114.0              51.0   \n10259                  0                36.0          33.0              15.0   \n10260                  0                 1.0           1.0               2.0   \n10268                  0                 0.0           1.0               1.0   \n\n       mostly_true_counts  pants_on_fire_counts  context  \n0                     0.0                   0.0       10  \n1                     1.0                   0.0        3  \n2                   163.0                   9.0       13  \n5                     5.0                   1.0       13  \n7                   163.0                   9.0        7  \n...                   ...                   ...      ...  \n10256                 0.0                   1.0        7  \n10257                37.0                  61.0        5  \n10259                19.0                   8.0        1  \n10260                 1.0                   1.0        1  \n10268                 0.0                   2.0        1  \n\n[6745 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>statement</th>\n      <th>job_title</th>\n      <th>party_affiliation</th>\n      <th>barely_true_counts</th>\n      <th>false_counts</th>\n      <th>half_true_counts</th>\n      <th>mostly_true_counts</th>\n      <th>pants_on_fire_counts</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>15</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>The Chicago Bears have had more starting quart...</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>\"I'm the only person on this stage who has wor...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10256</th>\n      <td>5</td>\n      <td>Recently though, the media has reported on tho...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>10257</th>\n      <td>4</td>\n      <td>Stopped by Smiley Cookie to pick up some great...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>63.0</td>\n      <td>114.0</td>\n      <td>51.0</td>\n      <td>37.0</td>\n      <td>61.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10259</th>\n      <td>4</td>\n      <td>The Supreme Courts views are radically out of ...</td>\n      <td>10</td>\n      <td>0</td>\n      <td>36.0</td>\n      <td>33.0</td>\n      <td>15.0</td>\n      <td>19.0</td>\n      <td>8.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10260</th>\n      <td>1</td>\n      <td>When it comes to the state deficit, Wisconsin ...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10268</th>\n      <td>5</td>\n      <td>The Department of Veterans Affairs has a manua...</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6745 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T17:00:00.374564Z",
     "start_time": "2024-04-06T17:00:00.365127Z"
    }
   },
   "id": "9d6a53cf3eec952",
   "execution_count": 247
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 文本清理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6738900fbd2745d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 定义清理文本的函数\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 移除标点符号\n",
    "    text = re.sub(r'\\d+', '', text)  # 移除数字\n",
    "    text = text.lower()  # 转换为小写\n",
    "    return text\n",
    "\n",
    "# 假设df是你的DataFrame，并且它有一个名为'statement'的列包含文本数据\n",
    "train_df['statement'] = train_df['statement'].apply(clean_text)\n",
    "test_df['statement'] = test_df['statement'].apply(clean_text)\n",
    "valid_df['statement'] = valid_df['statement'].apply(clean_text)\n",
    "\n",
    "train_df.to_csv('dataset/after_train.csv', index=False)\n",
    "test_df.to_csv('dataset/after_test.csv', index=False)\n",
    "valid_df.to_csv('dataset/after_valid.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T17:00:01.568408Z",
     "start_time": "2024-04-06T17:00:01.493839Z"
    }
   },
   "id": "df6bdf197bdf0787",
   "execution_count": 248
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 文本向量化 TF_IDF\n",
    "使用fit_transform方法来拟合向量化器，并基于训练数据构建TF-IDF模型。对于测试集和验证集，应使用transform方法来转换文本数据。\n",
    "將訓練集數據轉換成TF-IDF向量，得到了一個「稀疏矩陣」，涉及大量数据时节省内存的有效方式，因为它只存储非零元素的信息。\n",
    "已经有了向量化后的数据，可以开始使用这些数据来训练机器学习模型了。\n",
    "\n",
    "\n",
    "#### 解讀稀疏矩陣\n",
    "6745：表示有6745個文本数据点（如新闻文章、评论等）被转换成了向量。\n",
    "10371：表示在所有文本數據中，向量化器识别出了10371个唯一词项构成的词汇表。\n",
    "128201：在所有转换后的向量中，共有128201个非零TF-IDF值，意味着这些词在对应的文档中至少出现过一次，并且具有一定的重要性。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e67cb474fb9e36bc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\n# 实例化TF-IDF向量化器\\ntfidf_vectorizer = TfidfVectorizer()\\n\\n# 使用訓練數據擬合TF-IDF向量化器，並轉換為訓練數據\\n# 假设已经創建了一个名為\\'cleaned_text\\'的列，通過合併\\'context\\'和\\'statement\\'得到\\ntrain_df[\\'clean_statement\\'] = train_df[\\'statement\\'] + \" \" + train_df[\\'context\\']\\ntfidf_train_vectors = tfidf_vectorizer.fit_transform(train_df[\\'clean_statement\\'])\\n\\ntest_df[\\'clean_statement\\'] = test_df[\\'statement\\'] + \" \" + test_df[\\'context\\']\\ntfidf_test_vectors = tfidf_vectorizer.transform(test_df[\\'clean_statement\\'])\\n\\nvalid_df[\\'clean_statement\\'] = valid_df[\\'statement\\'] + \" \" + valid_df[\\'context\\']\\ntfidf_valid_vectors = tfidf_vectorizer.transform(valid_df[\\'clean_statement\\'])\\n\\n# drop掉context和statement\\ntrain_df = train_df.drop(columns=[\\'context\\', \\'statement\\'])\\ntest_df = test_df.drop(columns=[\\'context\\', \\'statement\\'])\\nvalid_df = valid_df.drop(columns=[\\'context\\', \\'statement\\'])\\n\\nprint(tfidf_train_vectors)\\ntrain_df\\n'"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 实例化TF-IDF向量化器\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 使用訓練數據擬合TF-IDF向量化器，並轉換為訓練數據\n",
    "# 假设已经創建了一个名為'cleaned_text'的列，通過合併'context'和'statement'得到\n",
    "train_df['clean_statement'] = train_df['statement'] + \" \" + train_df['context']\n",
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(train_df['clean_statement'])\n",
    "\n",
    "test_df['clean_statement'] = test_df['statement'] + \" \" + test_df['context']\n",
    "tfidf_test_vectors = tfidf_vectorizer.transform(test_df['clean_statement'])\n",
    "\n",
    "valid_df['clean_statement'] = valid_df['statement'] + \" \" + valid_df['context']\n",
    "tfidf_valid_vectors = tfidf_vectorizer.transform(valid_df['clean_statement'])\n",
    "\n",
    "# drop掉context和statement\n",
    "train_df = train_df.drop(columns=['context', 'statement'])\n",
    "test_df = test_df.drop(columns=['context', 'statement'])\n",
    "valid_df = valid_df.drop(columns=['context', 'statement'])\n",
    "\n",
    "print(tfidf_train_vectors)\n",
    "train_df\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T17:00:02.823723Z",
     "start_time": "2024-04-06T17:00:02.820442Z"
    }
   },
   "id": "46a3f225cde06487",
   "execution_count": 249
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba8ca27d79167ddb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BERT的文本處理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d941afc82349d96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# 加载预训练的Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 假设train_df, test_df, valid_df已根据您的指示进行了加载和预处理\n",
    "# 例如，这里我们假设已经完成了清理文本的步骤\n",
    "\n",
    "# 函数：将文本转换为BERT模型的输入格式\n",
    "def encode_sentences(tokenizer, sentences, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sentence,                      # 输入文本\n",
    "                            add_special_tokens=True,       # 添加 '[CLS]' 和 '[SEP]'\n",
    "                            max_length=max_length,         # 填充 & 截断长度\n",
    "                            padding='max_length',          # 填充至最大长度\n",
    "                            truncation=True,               # 显式激活截断\n",
    "                            return_attention_mask=True,    # 构造注意力掩码\n",
    "                            return_tensors='tf',           # 返回tensorflow张量\n",
    "                      )\n",
    "        \n",
    "        # 添加编码后的句子\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        # 和对应的注意力掩码（区分padding与非padding）\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # 转换为tensorflow格式\n",
    "    input_ids = tf.concat(input_ids, axis=0)\n",
    "    attention_masks = tf.concat(attention_masks, axis=0)\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\n",
    "# 编码数据集\n",
    "max_length = 128  # 可以根据需要调整\n",
    "train_inputs, train_masks = encode_sentences(tokenizer, train_df['statement'].tolist(), max_length)\n",
    "valid_inputs, valid_masks = encode_sentences(tokenizer, valid_df['statement'].tolist(), max_length)\n",
    "test_inputs, test_masks = encode_sentences(tokenizer, test_df['statement'].tolist(), max_length)\n",
    "\n",
    "# 将标签转换为tensorflow格式\n",
    "train_labels = tf.convert_to_tensor(train_df['label'].tolist())\n",
    "valid_labels = tf.convert_to_tensor(valid_df['label'].tolist())\n",
    "test_labels = tf.convert_to_tensor(test_df['label'].tolist())\n",
    "\n",
    "# 接下来，您可以根据这些准备好的输入和标签来定义和训练您的TensorFlow模型。\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T20:16:27.310215Z",
     "start_time": "2024-04-05T20:16:24.955441Z"
    }
   },
   "id": "dfa2b67649b995e5",
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  1/211 [..............................] - ETA: 1:12:16 - loss: 1.8978 - accuracy: 0.1250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[238], line 45\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00meval_result[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00meval_result[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model, history\n\u001B[0;32m---> 45\u001B[0m model, history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_evaluate_bert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_masks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_masks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_masks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[238], line 28\u001B[0m, in \u001B[0;36mtrain_and_evaluate_bert\u001B[0;34m(train_inputs, train_masks, train_labels, valid_inputs, valid_masks, valid_labels, test_inputs, test_masks, test_labels, num_labels, learning_rate, epochs, batch_size)\u001B[0m\n\u001B[1;32m     22\u001B[0m valid_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices((\n\u001B[1;32m     23\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m: valid_inputs, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: valid_masks},\n\u001B[1;32m     24\u001B[0m     valid_labels\n\u001B[1;32m     25\u001B[0m ))\u001B[38;5;241m.\u001B[39mbatch(batch_size)\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# 评估模型\u001B[39;00m\n\u001B[1;32m     35\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices((\n\u001B[1;32m     36\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m: test_inputs, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: test_masks},\n\u001B[1;32m     37\u001B[0m     test_labels\n\u001B[1;32m     38\u001B[0m ))\u001B[38;5;241m.\u001B[39mbatch(batch_size)\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1170\u001B[0m, in \u001B[0;36mTFPreTrainedModel.fit\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(keras\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mfit)\n\u001B[1;32m   1168\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1169\u001B[0m     args, kwargs \u001B[38;5;241m=\u001B[39m convert_batch_encoding(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1170\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py:1804\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1796\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1797\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1798\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1801\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1802\u001B[0m ):\n\u001B[1;32m   1803\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1804\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1806\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    868\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 869\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    875\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1498\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1500\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1505\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1506\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1508\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1509\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1510\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1514\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1515\u001B[0m   )\n",
      "File \u001B[0;32m~/Documents/彰師大/02 私自學習/Machine Learning/Side Project/FakeNewsDetection/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "def train_and_evaluate_bert(train_inputs, train_masks, train_labels, valid_inputs, valid_masks, valid_labels, test_inputs, test_masks, test_labels, num_labels=6, learning_rate=5e-5, epochs=3, batch_size=32):\n",
    "    # 加载预训练的BERT模型，适配于序列分类任务\n",
    "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "    \n",
    "    # 对于M1/M2 Mac用户，使用legacy版本的Adam优化器以获得更好的性能\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "    \n",
    "    # 将数据包装进tf.data.Dataset中以便训练\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {'input_ids': train_inputs, 'attention_mask': train_masks},\n",
    "        train_labels\n",
    "    )).shuffle(100).batch(batch_size)\n",
    "\n",
    "    valid_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {'input_ids': valid_inputs, 'attention_mask': valid_masks},\n",
    "        valid_labels\n",
    "    )).batch(batch_size)\n",
    "\n",
    "    # 训练模型\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # 评估模型\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {'input_ids': test_inputs, 'attention_mask': test_masks},\n",
    "        test_labels\n",
    "    )).batch(batch_size)\n",
    "\n",
    "    eval_result = model.evaluate(test_dataset)\n",
    "    print(f\"Test loss: {eval_result[0]}, Test accuracy: {eval_result[1]}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "model, history = train_and_evaluate_bert(train_inputs, train_masks, train_labels, valid_inputs, valid_masks, valid_labels, test_inputs, test_masks, test_labels)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T20:32:18.683393Z",
     "start_time": "2024-04-05T20:31:45.396859Z"
    }
   },
   "id": "cc051d56cf07e8bb",
   "execution_count": 238
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 顯示關鍵字圖片"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5096c4830f54360f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfrom wordcloud import WordCloud\\nimport matplotlib.pyplot as plt\\n\\n# 繪製文字雲圖像\\ndef wordFigure(text):\\n    text = \" \".join([sentence for sentence in text])\\n    wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(text)\\n    plt.figure(figsize=(15, 9))  # 設定圖片大小為15x9英寸\\n    plt.imshow(wordcloud, interpolation=\\'bilinear\\')  # 顯示文字雲，使用雙線性插值法讓顯示更平滑\\n    plt.axis(\\'off\\')  # 不顯示軸標籤\\n    plt.show()  # 顯示圖像\\n    \\n\\nprint(wordFigure(train_df[\\'statement\\']))\\nprint(wordFigure(train_df[\\'statement\\'][train_df[\\'label\\']==5]))\\nprint(wordFigure(train_df[\\'statement\\'][train_df[\\'label\\']==3]))\\n'"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 繪製文字雲圖像\n",
    "def wordFigure(text):\n",
    "    text = \" \".join([sentence for sentence in text])\n",
    "    wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(text)\n",
    "    plt.figure(figsize=(15, 9))  # 設定圖片大小為15x9英寸\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')  # 顯示文字雲，使用雙線性插值法讓顯示更平滑\n",
    "    plt.axis('off')  # 不顯示軸標籤\n",
    "    plt.show()  # 顯示圖像\n",
    "    \n",
    "\n",
    "print(wordFigure(train_df['statement']))\n",
    "print(wordFigure(train_df['statement'][train_df['label']==5]))\n",
    "print(wordFigure(train_df['statement'][train_df['label']==3]))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:50:40.881887Z",
     "start_time": "2024-04-05T18:50:40.879273Z"
    }
   },
   "id": "6ee5fd67f87410e1",
   "execution_count": 178
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f40f6c05733f1e53"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5edfdb8e5f527b2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
